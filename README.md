# Trends and Apps for CV Course Project

This module implements a Computer Vision pipeline to detect lip-sync-based deepfakes by analyzing the consistency between phonemes (audio) and visemes (lip movement).

## Table of contents

- [Project structure](#project-structure)
- [Project setup](#project-setuo)
- [How to run](#how-to-run)
- [Authors](#authors)

## Project structure

The project is organized to clearly separate data, code, and scripts:

* `dataset/`: Contains all data.
* `init/`: Original datasets (e.g., s1, s2) and raw files.
* `output/`: Files generated by the pipeline (MFA alignments, video embeddings, gold dictionaries).


* `src/`: Module source code (core logic).
* `prepare_dataset/`: Numbered scripts (step1 -> step4) to build the dataset and train the references.
* `scripts/`: Tools for final use (video audit, security tests).

## Project setup

To ensure compatibility between different tools (MFA requires an older Python version, Torch prefers a newer one), we use a two-tier approach:

### 1. Conda - `mfa` & `ffmpeg`

We use Conda to install system binaries and the Montreal Forced Aligner.

```bash
# Create the base environment with system dependencies
conda env create -f environment.yml

# Activate the environment
conda activate deepfake_cv_env

# Verify that mfa works
mfa version

```

### 2. Python Venv - `torch`, `opencv`

We use a local virtual environment for the project's Python libraries.

```bash
# Create the base environment with system dependencies
conda env create -f environment.yml

# Activate the environment
conda activate deepfake_cv_env

# Verify that mfa works
mfa version

# Create the venv (if it doesn't exist)
python -m venv .venv

# Activate the venv
source .venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

```

> **IMPORTANT**: When running Python scripts, ensure you are inside the `.venv`. When using `mfa` from the command line, ensure the Conda environment is active.

## How to run

To launch the demo, execute:

```bash
python test/demo.py
```

Once the script is run, the results of the analysis for each video and the overall summary will be displayed in the console and saved in the `test` directory in `demo_results.json`.

## Authors

| Name | Email |
| --- | --- |
| Stefano Camposilvan | stefano.camposilvan@studenti.unitn.it |
| Alessandro De Vidi | alessandro.devidi@studenti.unitn.it |
| Carlo Zamuner | carlo.zamuner@studenti.unitn.it |